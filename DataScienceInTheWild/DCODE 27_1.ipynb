{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f280652a",
   "metadata": {},
   "source": [
    "Welcome to Data Science in the Wild! In today's tutorial, we'll start by reviewing some basics in Python that we'll use along with several packages to load, clean, analyse, and plot a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac92c1",
   "metadata": {},
   "source": [
    "1. Print statements and simple calculations\n",
    "\n",
    "First, let's review the print() function by introducing ourselves. Fill in the following line of code with your information, and then click \"Run.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43845c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello, world! My name is [[enter your name]] and I am a PhD student at [[enter your affiliation]].')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06174d93",
   "metadata": {},
   "source": [
    "We can also use print statements for calculations. Let's have Python do some basic maths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(40/2)\n",
    "print(40//2)\n",
    "print(100*845)\n",
    "print(5-8+4)\n",
    "print(5-(8+4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f340ba",
   "metadata": {},
   "source": [
    "The final two equations show us that Python follows the order of operations. We won't go over maths today, but remember this in your calculations.\n",
    "\n",
    "Do you notice anything else about the outputs for these equations? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc5020",
   "metadata": {},
   "source": [
    "2. Data types and values\n",
    "\n",
    "Python stores information as strings, integers, and floats. \n",
    "\n",
    "-Strings are enclosed in quotation marks and are often used for textual data, like 'Hello, world!' in our first example. \n",
    "-Integers are whole numbers without decimal points. Integers can be positive or negative. \n",
    "-Floats, AKA \"floating-point numbers,\" contain decimal points.\n",
    "\n",
    "Sometimes, you can run into mixed variable type errors. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('20' + 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036c90e",
   "metadata": {},
   "source": [
    "To fix these errors, you can check the type of an input. You can also convert between data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564744a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(20.0))\n",
    "print(type(84500))\n",
    "print(type('Hello, world!'))\n",
    "\n",
    "print(int(20.0))\n",
    "print(float(84500))\n",
    "print(str(547))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33c18e0d",
   "metadata": {},
   "source": [
    "To store data, we can assign it to a specific variable. This can be really handy when you're working with a lot of data.\n",
    " \n",
    "Let's store one of each type of data in three different variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_float=89.76\n",
    "my_int=140\n",
    "my_str='Today is Friday.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e63fb1",
   "metadata": {},
   "source": [
    "After storing a variable, we can reference it again by name. We can also combine stored variables with new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa5220",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('What day is today?' + my_str)\n",
    "print('What day is today?' + ' ' + my_str)\n",
    "\n",
    "my_float + my_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b62954",
   "metadata": {},
   "source": [
    "3. Storing data: lists, dictionaries, and dataframes\n",
    "\n",
    "There are many ways to store information in Python. A list stores multiple items in one variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_list=['espresso', 'latte', 'macchiato', 'mocha', 'americano']\n",
    "print(coffee_list[2])\n",
    "print(coffee_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ad47b",
   "metadata": {},
   "source": [
    "A dictionary stores information in key:value format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_dict={'Tokyo':'Japan', 'Toronto':'Canada', 'Istanbul':'Turkey', 'Mexico City':'Mexico', 'Cairo':'Egypt'}\n",
    "city_dict.update({'Paris':'France'})\n",
    "print(city_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5b1c3",
   "metadata": {},
   "source": [
    "We can also store information in a dataframe. For this, we'll need to call the DataFrame function in pandas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ccb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "shopping_list=['potatoes', 'carrots', 'apples', 'onions', 'tomatoes']\n",
    "food_quantity=[3, 5, 2, 4, 10]\n",
    "df=pd.DataFrame(shopping_list, food_quantity)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ec5bd",
   "metadata": {},
   "source": [
    "The dataframe holds our information, but it still needs some work. Let's add an index and column titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cd74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True, drop = False)\n",
    "df=df.rename(columns={'index':'Quantity', 0:'Food'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0275eae",
   "metadata": {},
   "source": [
    "Some other useful dataframe functions are as follows--try them on your own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.drop(columns='Food'))\n",
    "    #removes the selected column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "    #column info, dimensions, types of data in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c88c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[1:3])\n",
    "    #slices dataframe from index position 1 up until (but *not* including!) position 3-->AKA positions 1 & 2 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(2))\n",
    "    #slices first 2 rows from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.tail(2))\n",
    "    #slices final 2 rows from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9130f681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['Food'].sort_values(ascending=False))\n",
    "    #sorts the 'Food' column reverse alphabetically. also applies to numerical values in float and int data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aedf85",
   "metadata": {},
   "source": [
    "4. Conditionals, counters, comparisons, and loops\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd712bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for drink in coffee_list:\n",
    "    if drink=='latte':\n",
    "        print(\"I'll have a latte.\")\n",
    "    else:\n",
    "        print(\"I'll have a cup of tea.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in city_dict:\n",
    "  print(key + \" is a city in \" + city_dict[key] + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_list=[20, 40, 60, 80, 100]\n",
    "counter = 0\n",
    "\n",
    "for i in integer_list:\n",
    "    if i + 15 < 90:\n",
    "        counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f57d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['cat', 'dog', 'ferret', 'goldfish', 'gecko', 'rabbit']\n",
    "\n",
    "'tortoise' in animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e741d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tortoise=False\n",
    "\n",
    "if tortoise:\n",
    "    print ('I have a pet tortoise.')\n",
    "elif not tortoise:\n",
    "    print (\"I don't have a pet tortoise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdfaa04",
   "metadata": {},
   "source": [
    "These expressions can be useful for checking for information and errors in complex dataframes. We'll try some simple exercises using the df we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_and_veg=['bananas', 'apples', 'potatoes', 'onions']\n",
    "counter=0\n",
    "\n",
    "for i in df['Food']:\n",
    "    if i in fruits_and_veg:\n",
    "        counter += 1\n",
    "    else:\n",
    "        print(\"We don't need to buy any \" + i + \" this week.\")\n",
    "print(\"There are \" + counter + \" items on the shopping list this week.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48554a57",
   "metadata": {},
   "source": [
    "Can you diagnose the error above? How should we fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3cd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \" + str(counter) + \" items on the shopping list this week.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d052569",
   "metadata": {},
   "source": [
    "Part II: Wrangling Data\n",
    "\n",
    "A. Importing and Exploring Data\n",
    "\n",
    "We'll start by importing the packages needed for today's lesson. Then, we'll use pandas to load our data to a dataframe, which we'll call \"df.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f1999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv('/Users/jessicawitte/DCODE_Data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bd5e6",
   "metadata": {},
   "source": [
    "After you load a dataset, you can get a summary of its contents with .info(). This is a great feature to remember if you ever find yourself working with extremely large datasets that can't be loaded into Excel or Google Docs.\n",
    "\n",
    ".iloc[] allows you to print a \"slice\" of the dataframe. In this example, we are printing the fifth row of the dataframe. You can also print ranges (e.g. df.iloc[5:10]) or slice from the end of the dataframe (df.iloc[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289df5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fb452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98106b7f",
   "metadata": {},
   "source": [
    "From the output of these lines, what can you observe about the dataset? For instance:\n",
    "\n",
    "1. How many rows and columns are present?\n",
    "2. What does the \"Non-Null Count\" mean?\n",
    "3. What types of data are in the columns?\n",
    "4. Are the columns labelled? Are the labels appropriate?\n",
    "5. Do you see any evidence of errors or gaps in the data?\n",
    "6. Is the formatting uniform/standard?\n",
    "\n",
    "Datasets are unique, and so the cleaning process can't be entirely standardized for every situation. The questions above can help you determine what needs to be adjusted on your dataset before you can move on to the next phase of your project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d58207e",
   "metadata": {},
   "source": [
    "We can print information about a column with .describe(). Note that the output differs depending on the dtype stored in the column:\n",
    "\n",
    "*A quick note about \"dtypes\"*: dtypes are not *exactly* equivalent to \"types\" in Python. We won't get into specifics in this tutorial, but the differences have to do with how the computer reads pixels in complex data structures. \n",
    "Like type errors, dtype errors are very common, so you might need to convert between them. dtypes int64 and float64 are similar to types int and float; dtypes of the object class typically store textual data, like tupe str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a51ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Area of UK'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['love-island-series'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751f506",
   "metadata": {},
   "source": [
    "B. Cleaning Data\n",
    "\n",
    "Now that we have an idea of what our data contains, let's do some basic cleaning. Cleaning processes will differ depending upon the next steps in our analysis. For instance, cleaning data for text mining often involves stemming and lemmatizing textual data. For our purposes, we're going to be plotting our data. This means that we need to standardize numerical data, perform simple calculations, remove irrelevant data, and check for errors.  First, let's check for any null or NaN values. We won't be able to graph numerical data that contains null values, so this step is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf607fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum().sum())\n",
    "\n",
    "df.isna().any()[lambda x: x]\n",
    "\n",
    "#https://www.w3schools.com/python/python_lambda.asp is a great resource for more about the lambda function. \n",
    "#In short, this is a small function contained to one line, meaning you can't call it again without running\n",
    "#the same code. Lambda functions are helpful in text cleaning, when you're performing a quick check that \n",
    "#won't be repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556aaa65",
   "metadata": {},
   "source": [
    "So, there are 202 null values in six columns.\n",
    "\n",
    "\n",
    "Let's try performing a calculation with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58378599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of dates'].iloc[0:5].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e165e69",
   "metadata": {},
   "source": [
    "We can replace NaNs with 0s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(np.nan,0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db99bbc",
   "metadata": {},
   "source": [
    "Now, no null values exist. But it looks like replacing the NaN values have changed the dtypes of the affected columns.\n",
    "Let's check the output of one of the columns and standardize our dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb580917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f35dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == 'float64':\n",
    "        df[column] = df[column].astype(np.int64)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5104498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0adf6",
   "metadata": {},
   "source": [
    "The column titles in our dataset could be improved. We'll also want to standardize the capitalization in our data. We'll capitalize the first word of data in our \n",
    "(note: see more pandas functions related to capitalization here https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_caps(df):\n",
    "    df = df.apply(lambda x: x.str.title() if x.dtype == \"object\" else x) \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be37c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=standard_caps(df)\n",
    "df.iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d82ad",
   "metadata": {},
   "source": [
    "Let's also address the capitalization in the column titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fe8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = map(str.title, df.columns)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d372de",
   "metadata": {},
   "source": [
    "We can see what's in a column by printing df['column title'], but sometimes the output is too large to be displayd in Python. We can use .unique() to print one instance of each value in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665bca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=df['Profession'].unique()\n",
    "print(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages=df['Age'].unique()\n",
    "print(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c13ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cities=df['From'].unique()\n",
    "print(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6fa86a",
   "metadata": {},
   "source": [
    "Take a look the output of \"cities.\" Do you see any errors that we should address before moving on to our plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c582d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.isin(['Scotland']).any(axis=1)].index.tolist()\n",
    "#Python looks for 'Scotland' anywhere in the dataframe and prints the location in the format [row, col]. So, we \n",
    "#know the error is in row 28.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[28]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a0f462",
   "metadata": {},
   "source": [
    "In a small dataset, it's easy to manual correct errors. In this case, we can try Google to learn where in Scotland the contestant was born. According to Wikipedia, she is from Dumfries. We can manually correct this in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1db553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[28, 'From'] = 'Dumfries'\n",
    "df.iloc[28]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6970f847",
   "metadata": {},
   "source": [
    "For our final step in cleaning today, we'll edit the column names so they're more concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a26ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={\"Day Left Villa\": \"Last Day\", \"Day Joined Villa\": \"First Day\", \n",
    "                      \"Was Longest Couple Final Couple\":\"Longest/Final Couple\", \n",
    "                      \"Love-Island-Series\":\"Series Year\"})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cba248",
   "metadata": {},
   "source": [
    "We have a list of the contestants' ages, and we can calculate formulas such as standard deviation and mean computationally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fbb6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8ff3c",
   "metadata": {},
   "source": [
    "But for certain research questions, we need to know the frequency of the distribution of the data. We can do this with .value_counts(), which creates a frequency table of unique values as an array. With a few more lines of code, we can format the array as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012a4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_counts=df['Age'].value_counts()\n",
    "df_ages=pd.DataFrame(data=age_counts)\n",
    "df_ages=df_ages.reset_index(drop=False)\n",
    "df_ages=df_ages.rename(columns={'index':'Age', 'Age':'Count'})\n",
    "\n",
    "print(df_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5cf82",
   "metadata": {},
   "source": [
    "Part C: Plotting Data\n",
    "\n",
    "We're ready for our first plot, which we'll format as a simple barplot in Seaborn. (note: Seaborn, which runs on top of MatPlotLib, can create very interesting visualizations for a variety of datasets. Here is a gallery: https://seaborn.pydata.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3accf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df_ages, x=\"Age\", y=\"Count\")\n",
    "plt.title('Ages of \"Love Island\" Contestants')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54b39e",
   "metadata": {},
   "source": [
    "Barplots, also known as histograms, are good for categorical data (in other words, sorting data into categories and measuring the size, percentage, or quantity or each category). Even though we are organising our data by number, each age functions as a category in this case. \n",
    "\n",
    "Let's try plotting numerical data. We'll use Seaborn to make a scatterplot to see whether the amount of time a contestant spent in the villa affected how many dates they got during the series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c059a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Number Of Days In Villa\", y=\"Number Of Dates\", hue=\"Series Year\", alpha=.5, palette=\"bright\",\n",
    "            height=6, data=df)\n",
    "plt.title('Days vs. Dates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910683a6",
   "metadata": {},
   "source": [
    "We can also change the size of the scatter points as another variable in Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b34f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Number Of Days In Villa\", y=\"Number Of Dates\", hue=\"Series Year\", \n",
    "            size='Number Of Challenges Won', sizes=(40,400), alpha=.5, \n",
    "            height=6, data=df)\n",
    "plt.title('Days vs. Dates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c466d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
