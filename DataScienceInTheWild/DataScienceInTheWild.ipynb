{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IOmlzK-dX4IE"
      },
      "id": "IOmlzK-dX4IE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Science in the Wild**"
      ],
      "metadata": {
        "id": "-mjUdO5eYdO5"
      },
      "id": "-mjUdO5eYdO5"
    },
    {
      "cell_type": "markdown",
      "id": "75834b93",
      "metadata": {
        "id": "75834b93"
      },
      "source": [
        "Welcome to Data Science in the Wild! In today's tutorial, we'll start by reviewing some basics in Python that we'll use along with several packages to load, clean, analyse, and plot a dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe73a39d",
      "metadata": {
        "id": "fe73a39d"
      },
      "source": [
        "1. Print statements and simple calculations\n",
        "\n",
        "First, let's review the print() function by introducing ourselves. Fill in the following line of code with your information, and then click \"Run.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f27153",
      "metadata": {
        "id": "e0f27153"
      },
      "outputs": [],
      "source": [
        "print('Hello, world! My name is [[enter your name]] and I am a PhD student at [[enter your affiliation]].')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db813738",
      "metadata": {
        "id": "db813738"
      },
      "source": [
        "We can also use print statements for calculations. Let's have Python do some basic maths:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64660e84",
      "metadata": {
        "id": "64660e84"
      },
      "outputs": [],
      "source": [
        "print(40/2)\n",
        "print(100*845)\n",
        "print(5-8+4)\n",
        "print(5-(8+4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e41925e9",
      "metadata": {
        "id": "e41925e9"
      },
      "source": [
        "The final two equations show us that Python follows the order of operations. We won't go over maths today, but remember this in your calculations.\n",
        "\n",
        "Do you notice anything else about the outputs for these equations? "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1301067c",
      "metadata": {
        "id": "1301067c"
      },
      "source": [
        "2. Variable types and assigning values\n",
        "\n",
        "Python stores information as strings, integers, and floats. \n",
        "\n",
        "-Strings are enclosed in quotation marks and are often used for textual data, like 'Hello, world!' in our first example. \n",
        "-Integers are whole numbers without decimal points. Integers can be positive or negative. \n",
        "-Floats, AKA \"floating-point numbers,\" contain decimal points.\n",
        "\n",
        "Sometimes, you can run into mixed variable type errors. Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b17555bf",
      "metadata": {
        "id": "b17555bf"
      },
      "outputs": [],
      "source": [
        "print('20' + 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bd33d3d",
      "metadata": {
        "id": "2bd33d3d"
      },
      "source": [
        "To fix these errors, you can check the type of an input. You can also convert between data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6b7f278",
      "metadata": {
        "id": "f6b7f278"
      },
      "outputs": [],
      "source": [
        "type(20.0)\n",
        "type(84500)\n",
        "type('Hello, world!')\n",
        "\n",
        "int(20.0)\n",
        "float(84500)\n",
        "str(547)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2e36fc6",
      "metadata": {
        "id": "d2e36fc6"
      },
      "source": [
        "To store data, we can assign it to a specific variable. This can be really handy when you're working with a lot of data.\n",
        " \n",
        "Let's store one of each type of data in three different variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d147c4",
      "metadata": {
        "id": "f9d147c4"
      },
      "outputs": [],
      "source": [
        "my_float=89.76\n",
        "my_int=140\n",
        "my_str='Today is Friday.'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52d8dcce",
      "metadata": {
        "id": "52d8dcce"
      },
      "source": [
        "After storing a variable, we can reference it again by name. We can also combine stored variables with new information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9599ec",
      "metadata": {
        "id": "2b9599ec"
      },
      "outputs": [],
      "source": [
        "print('What day is today?' + my_str)\n",
        "print('What day is today?' + ' ' + my_str)\n",
        "\n",
        "my_float + my_int"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1e522f",
      "metadata": {
        "id": "3d1e522f"
      },
      "source": [
        "3. Storing data: lists, dictionaries and dataframes\n",
        "\n",
        "There are many ways to store information in Python. A list stores multiple items in one variable. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e58130ce",
      "metadata": {
        "id": "e58130ce"
      },
      "outputs": [],
      "source": [
        "coffee_list=['espresso', 'latte', 'macchiato', 'mocha', 'americano']\n",
        "print(coffee_list[2])\n",
        "print(coffee_list[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a76d14b0",
      "metadata": {
        "id": "a76d14b0"
      },
      "source": [
        "A dictionary stores information in key:value format. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e800a50",
      "metadata": {
        "id": "7e800a50"
      },
      "outputs": [],
      "source": [
        "city_dict={'Tokyo':'Japan', 'Toronto':'Canada', 'Istanbul':'Turkey', 'Mexico City':'Mexico', 'Cairo':'Egypt'}\n",
        "city_dict.update({'Paris':'France'})\n",
        "print(city_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5fce33",
      "metadata": {
        "id": "5a5fce33"
      },
      "outputs": [],
      "source": [
        "We can also store information in a dataframe. For this, we'll need to call the DataFrame function in pandas. \n",
        "\n",
        "import pandas as pd\n",
        "shopping_list=['potatoes', 'carrots', 'apples', 'onions', 'tomatoes']\n",
        "food_quantity=[3, 5, 2, 4, 10]\n",
        "df=pd.DataFrame(shopping_list, food_quantity)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59ffd9fe",
      "metadata": {
        "id": "59ffd9fe"
      },
      "source": [
        "The dataframe holds our information, but it still needs some work. Let's add an index and column titles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a01577f7",
      "metadata": {
        "id": "a01577f7"
      },
      "outputs": [],
      "source": [
        "df.reset_index(inplace = True, drop = False)\n",
        "df=df.rename(columns={'index':'Quantity', 0:'Food'})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c29810a",
      "metadata": {
        "id": "3c29810a"
      },
      "source": [
        "Some other useful dataframe functions are as follows--try them on your own:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "743b1e64",
      "metadata": {
        "id": "743b1e64"
      },
      "outputs": [],
      "source": [
        "     df.drop(columns='Food')\n",
        "    #removes the selected column\n",
        "\n",
        "    df.info()\n",
        "    #column info, dimensions, types of data in df\n",
        "    \n",
        "    df.iloc[1:3]\n",
        "    #slices dataframe from index position 1 up until (but *not* including!) position 3-->AKA positions 1 & 2 only\n",
        "    \n",
        "    df.head(2)\n",
        "    #slices first 2 rows from dataframe\n",
        "    \n",
        "    df.tail(2)\n",
        "    #slices final 2 rows from dataframe\n",
        "    \n",
        "    df['Food'].sort_values(ascending=False)\n",
        "    #sorts the 'Food' column reverse alphabetically. also applies to numerical values in float and int data types"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97c4f8d5",
      "metadata": {
        "id": "97c4f8d5"
      },
      "source": [
        "There is so much more we can do with pandas and dataframes in Python! We'll go over some detailed applications \n",
        "in the next part of the tutorial. If you feel overwhelmed, don't worry--after some time practicing data analysis,\n",
        "it all gets much easier! \n",
        "\n",
        "Don't be afraid to ask for help. And when you're working on your own, StackOverflow and Google are your friends! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf9275a",
      "metadata": {
        "id": "0bf9275a"
      },
      "source": [
        "Part II: Wrangling Data\n",
        "\n",
        "A. Importing and Exploring Data\n",
        "\n",
        "We'll start by importing the packages needed for today's lesson. Then, we'll use pandas to load our data to a dataframe, which we'll call \"df.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c6d25f",
      "metadata": {
        "id": "e1c6d25f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df=pd.read_csv('/path_to_file.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c69c7e47",
      "metadata": {
        "id": "c69c7e47"
      },
      "source": [
        "After you load a dataset, you can get a summary of its contents with .info(). This is a great feature to remember if you ever find yourself working with extremely large datasets that can't be loaded into Excel or Google Docs.\n",
        "\n",
        ".iloc[] allows you to print a \"slice\" of the dataframe. In this example, we are printing the fifth row of the dataframe. You can also print ranges (e.g. df.iloc[5:10]) or slice from the end of the dataframe (df.iloc[-5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c33b800b",
      "metadata": {
        "id": "c33b800b"
      },
      "outputs": [],
      "source": [
        "df.info()\n",
        "df.iloc[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9505a635",
      "metadata": {
        "id": "9505a635"
      },
      "source": [
        "From the output of these lines, what can you observe about the dataset? For instance:\n",
        "\n",
        "1. How many rows and columns are present?\n",
        "2. What does the \"Non-Null Count\" mean?\n",
        "3. What types of data are in the columns?\n",
        "4. Are the columns labelled? Are the labels appropriate?\n",
        "5. Do you see any evidence of errors or gaps in the data?\n",
        "6. Is the formatting uniform/standard?\n",
        "\n",
        "Datasets are unique, and so the cleaning process can't be entirely standardized for every situation. The questions above can help you determine what needs to be adjusted on your dataset before you can move on to the next phase of your project.\n",
        "\n",
        "We can print information about a column with .describe(). Note that the output differs \n",
        "#depending on the dtype stored in the column:\n",
        "\n",
        "*A quick note about \"dtypes\"*: dtypes are not *exactly* equivalent to \"types\" in Python. We won't get into specifics in this tutorial, but the differences have to do with how the computer reads pixels in complex data structures. \n",
        "Like type errors, dtype errors are very common, so you might need to convert between them. dtypes int64 and float64 are similar to types int and float; dtypes of the object class typically store textual data, like tupe str."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3185f6a",
      "metadata": {
        "id": "a3185f6a"
      },
      "outputs": [],
      "source": [
        "df['Area of UK'].describe()\n",
        "df['love-island-series'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0f1dc98",
      "metadata": {
        "id": "b0f1dc98"
      },
      "source": [
        "B. Cleaning Data\n",
        "\n",
        "Now that we have an idea of what our data contains, let's do some basic cleaning. Cleaning processes will differ depending upon the next steps in our analysis. For instance, cleaning data for text mining often involves stemming and lemmatizing textual data. For our purposes, we're going to be plotting our data. This means that we need to standardize numerical data, perform simple calculations, remove irrelevant data, and check for errors.  First, let's check for any null or NaN values. We won't be able to graph numerical data that contains null values, so this step is important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ea72f2",
      "metadata": {
        "id": "e3ea72f2"
      },
      "outputs": [],
      "source": [
        "df.isnull().values.any()\n",
        "df.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccdbd870",
      "metadata": {
        "id": "ccdbd870"
      },
      "source": [
        "There are 26 NaN values in the 'Number of dates' column. We can replace them with 0s. Then, we'll need to convert the dtypes to int64 to remove the extra decimals in the numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4325898b",
      "metadata": {
        "id": "4325898b"
      },
      "outputs": [],
      "source": [
        "df['Number of dates']=df['Number of dates'].replace(np.nan,0)\n",
        "df['Number of dates']=df['Number of dates'].astype('int64')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc79d68f",
      "metadata": {
        "id": "dc79d68f"
      },
      "source": [
        "If you're working with a very large file, you might want to drop data that isn't relevant to your\n",
        "research question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e4a4a85",
      "metadata": {
        "id": "9e4a4a85"
      },
      "outputs": [],
      "source": [
        "df=df.drop(columns=['Area of UK', 'Number of Couples', 'Longest couple length'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11e1be42",
      "metadata": {
        "id": "11e1be42"
      },
      "source": [
        "The column titles in our dataset could be improved. We'll also want to standardize the capitalization in our data. We'll capitalize the first word of data in our \n",
        "(note: see more pandas functions related to capitalization here https://pandas.pydata.org/docs/reference/api/pandas.Series.str.capitalize.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f000a9",
      "metadata": {
        "id": "41f000a9"
      },
      "outputs": [],
      "source": [
        "df['OUTCOME']=df['OUTCOME'].str.capitalize()\n",
        "df['profession']=df['profession'].str.capitalize()\n",
        "df['Was longest couple final couple']=df['Was longest couple final couple'].str.capitalize()\n",
        "df.columns = map(str.title, df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8083d5a9",
      "metadata": {
        "id": "8083d5a9"
      },
      "source": [
        "We can see what's in a column by printing df['column title'], but sometimes the output is too large to be displayd in Python. We can use .unique() to print one instance of each value in a column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60a2653e",
      "metadata": {
        "id": "60a2653e"
      },
      "outputs": [],
      "source": [
        "jobs=df['Professions'].unique()\n",
        "ages=df['Age'].unique()\n",
        "cities=df['From'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8127ae45",
      "metadata": {
        "id": "8127ae45"
      },
      "source": [
        "Take a look at each of the three outputs. Do you see any errors, glitches, or problems that we should clean up before moving on to our plots?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f131675",
      "metadata": {
        "id": "2f131675"
      },
      "outputs": [],
      "source": [
        "df.loc[df.isin(['Scotland']).any(axis=1)].index.tolist()\n",
        "#Python looks for 'Scotland' anywhere in the dataframe and prints the location in the format [row, col]. So, we \n",
        "#know the error is in row 28.\n",
        "df.iloc[28]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9666012",
      "metadata": {
        "id": "e9666012"
      },
      "source": [
        "In a small dataset, it's easy to manual correct errors. In this case, we can try Google to learn where in Scotland the contestant was born. According to Wikipedia, she is from Dumfries. We can manually correct this in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c294fb1a",
      "metadata": {
        "id": "c294fb1a"
      },
      "outputs": [],
      "source": [
        "df.loc[28, 'From'] = 'Dumfries'\n",
        "df.iloc[28]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c52b31c",
      "metadata": {
        "id": "0c52b31c"
      },
      "source": [
        "We have a list of the contestants' ages, and we can calculate formulas such as standard deviation and mean computationally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "466abff3",
      "metadata": {
        "id": "466abff3"
      },
      "outputs": [],
      "source": [
        "df['Age'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7137953",
      "metadata": {
        "id": "c7137953"
      },
      "source": [
        "But for certain research questions, we need to know the frequency of the distribution of the data. We can do this with .value_counts(), which creates a frequency table of unique values as an array. With a few more lines of code, we can format the array as a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce2c2c4b",
      "metadata": {
        "id": "ce2c2c4b"
      },
      "outputs": [],
      "source": [
        "age_counts=df['Age'].value_counts()\n",
        "df_ages=pd.DataFrame(data=age_counts)\n",
        "df_ages=df_ages.reset_index(drop=False)\n",
        "df_ages=df_ages.rename(columns={'index':'Age', 'Age':'Count'})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe75a9e7",
      "metadata": {
        "id": "fe75a9e7"
      },
      "source": [
        "We're ready for our first plot, which we'll format as a simple barplot in Seaborn. (note: Seaborn, which runs on top of MatPlotLib, can create very interesting visualizations for a variety of datasets. Here is a gallery: https://seaborn.pydata.org)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b77b425",
      "metadata": {
        "id": "3b77b425"
      },
      "outputs": [],
      "source": [
        "Part C: Plotting Data\n",
        "\n",
        "sns.barplot(data=df_ages, x=\"Age\", y=\"Count\")\n",
        "plt.title('Ages of \"Love Island\" Contestants')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}